install.packages("tidyverse")
library(ggplot2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_point()
library(ggplot2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_histogram()
library(tidyverse)
#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
#> ✔ dplyr     1.1.2     ✔ readr     2.1.4
#> ✔ forcats   1.0.0     ✔ stringr   1.5.0
#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1
#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
#> ✔ purrr     1.0.1
#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
#> ✖ dplyr::filter() masks stats::filter()
#> ✖ dplyr::lag()    masks stats::lag()
#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
mpg
?mpg
library(ggplot2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_point()
library(ggplot2)
data <- data.frame(Category1 = rep(c("A", "B", "C"), each = 100),
Category2 = rep(c("X", "Y"), times = 150),
Percentage = c(runif(100, 0, 100), runif(100, 0, 100), runif(100, 0, 100)))
ggplot(data, aes(x = Category2, y = Percentage, fill = Category1)) +
geom_bar(stat = "identity", position = "dodge") +
facet_grid(Category1 ~ ., scales = "free_y", space = "free_y") +
labs(x = "Category 2", y = "Percentage") +
theme_minimal()
?paste0
?NaN
?NA
?NULL
"hello world"
"hello"
Hello
q()
"Hello"
print(paste0("The gene ", gene_name," is associated with a rare trait. Among ", num_individuals_tested," individuals studied, the trait is present in ", num_individuals_with_trait," individuals. The allele frequency is ", allele_frequency,".")
q()
q()
gene_name = "XYZ9"
allele_frequency = 0.126
num_individuals_tested = 145
num_individuals_with_trait = 12
print(paste0("The gene ", gene_name, " is associated with a rare trait. Among ", num_individuals_tested, " individuals studied, the trait is present in ", num_individuals_with_trait, " individuals. The allele frequency is ", allele_frequency, "."))
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
print(cellDivisionRate)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
install.packages("tibble")
install.packages("readr")
library(readr)
installed.packages()
install.packages("tidyverse")
source("~/.active-rstudio-document")
?summary.lm
install.packages("tensorflow")
install.packages('keras')
library(keras)
library(tensorflow)
library(keras)
install_keras()
mnist = dataset_mnist()
library(keras)
library(tensorflow)
install.packages("keras")
install.packages("keras")
library(tensorflow)
library(keras)
library(keras)
library(keras)
source("~/.active-rstudio-document")
install_keras()
q()
mnist = dataset_mnist()
remotes::install_github("rstudio/tensorflow")
# install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
reticulate::install_python()
install_tensorflow(envname = "r-tensorflow")
library(tensorflow)
install_tensorflow(envname = "r-tensorflow")
install.packages("keras")
library(keras)
install_keras()
library(tensorflow)
tf$constant("Hello TensorFlow!")
mnist = dataset_mnist()
install.packages("tidyverse")
library(tidyverse)
ggplot(tbl, aes(x = x)) +
geom_histogram()
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
library(tidyverse)
set.seed(33)
x = rnorm(10000)
tbl = tibble(x)
ggplot(tbl, aes(x = x)) +
geom_histogram() +
theme_bw()
source("~/.active-rstudio-document")
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
library(tidyverse)
set.seed(1)
x = runif(1000)
y = rnorm(1000)
print(x[:6])
library(tidyverse)
set.seed(1)
x = runif(1000)
y = rnorm(1000)
print(x[1:6])
print(y[1:6])
print(1*(log(.9)))
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
print(train_images)
train_images <- array_reshape(train_images, c(60000, 28 * 28))
print(train_images)
R.version.string
View(data)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
View(data)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
View(train_data)
View(train_data)
View(train_data)
View(train_data)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
View(test_data)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
View(test_X)
View(train_X)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
autoencoder_inputs = autoencoder$input
autoencoder_outputs = get_layer(autoencoder, "bottleneck")$output
autoencoder_bottleneck = keras_model(
inputs=autoencoder_inputs,
outputs=autoencoder_outputs
)
compressed_values = predict(autoencoder_bottleneck, train_X) %>%
print()
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
print(compressed_values, n=6)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
compressed_values = predict(autoencoder_bottleneck, train_X) %>%
as_tibble() %>%
rename(Bottleneck_1 = V1, Bottleneck_2 = V2) %>%
mutate(Species = train_data$Species) %>%
print()
compressed_values = predict(autoencoder_bottleneck, train_X)
compressed_tibble = as_tibble(compressed_values) %>%
rename(Bottleneck_1 = V1, Bottleneck_2 = V2) %>%
mutate(Species = train_data$Species) %>%
print()
compressed_tibble = as_tibble(compressed_values) %>%
rename(Bottleneck_1 = V1, Bottleneck_2 = V2) %>%
mutate(Species = train_data$Species)
ggplot(compressed_tibble, aes(x = Bottleneck_1, y = Bottleneck_2, color = Species)) +
geom_point() +
theme_bw() +
labs(x = "Bottleneck Dimension 1", y = "Bottleneck Dimension 2")
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
decoded_values <- predict(autoencoder, train_X)
decoded_tibble <- as_tibble(decoded_values)
decoded_tibble <- decoded_tibble %>%
mutate(Species = train_data$Species)
print(decoded_tibble)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
decoded_test_values <- predict(autoencoder, test_X)
decoded_test_tibble <- as_tibble(decoded_test_values)
decoded_test_tibble <- decoded_test_tibble %>%
mutate(Species = test_data$Species)
print(decoded_test_tibble)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
mod = rand_forest(trees = 100,
mode = "classification") %>%
set_engine("ranger")
recp = recipe(Species ~ ., data = decoded_tibble)
wf <- workflow() %>%
add_model(mod) %>%
add_recipe(recp)
fitted_model = fit(wf, data = decoded_tibble)
predictions_discrete = predict(fitted_model, decoded_tibble)
predictions = predictions_discrete %>%
bind_cols(decoded_tibble %>% select(Species))
acc = accuracy(predictions, truth = Species, estimate = .pred_class)
print(acc)
mod = rand_forest(trees = 100,
mode = "classification") %>%
set_engine("ranger")
recp = recipe(Species ~ ., data = decoded_test_tibble)
wf <- workflow() %>%
add_model(mod) %>%
add_recipe(recp)
fitted_model = fit(wf, data = decoded_test_tibble)
predictions_discrete = predict(fitted_model, decoded_test_tibble)
predictions = predictions_discrete %>%
bind_cols(decoded_test_tibble %>% select(Species))
acc = accuracy(predictions, truth = Species, estimate = .pred_class)
print(acc)
source("~/Desktop/bio564/hands_on_18A.R", echo=TRUE)
install.packages("reticulate")
source("~/.active-rstudio-document", echo=TRUE)
print(sentiment_analyzer("Machine learning is boring"))
print(sentiment_analyzer("Machine learning is lame"))
print(sentiment_analyzer("Machine learning is silly"))
print(sentiment_analyzer("Machine learning is neutral"))
print(sentiment_analyzer("Machine learning is decent"))
print(sentiment_analyzer("Machine learning is decent, but I don't really like it a lot.  I love Artificial Intelligence."))
print(sentiment_analyzer("Machine learning is decent, but I don't really like it a lot."))
print(sentiment_analyzer("Machine learning is decent, but I don't really like it that much"))
print(sentiment_analyzer("Machine learning is neutral"))
print(sentiment_analyzer("The elephant went to the park"))
summarizer = transformers$pipeline("summarization")
abstract = "Predicting the blood–brain barrier (BBB) permeability of small-molecule compounds using a novel artificial intelligence platform is necessary for drug discovery. Machine learning and a large language model on artificial intelligence (AI) tools improve the accuracy and shorten the time for new drug development. The primary goal of this research is to develop artificial intelligence (AI) computing models and novel deep learning architectures capable of predicting whether molecules can permeate the human blood–brain barrier (BBB). The in silico (computational) and in vitro (experimental) results were validated by the Natural Products Research Laboratories (NPRL) at China Medical University Hospital (CMUH). The transformer-based MegaMolBART was used as the simplified molecular input line entry system (SMILES) encoder with an XGBoost classifier as an in silico method to check if a molecule could cross through the BBB. We used Morgan or Circular fingerprints to apply the Morgan algorithm to a set of atomic invariants as a baseline encoder also with an XGBoost classifier to compare the results. BBB permeability was assessed in vitro using three-dimensional (3D) human BBB spheroids (human brain microvascular endothelial cells, brain vascular pericytes, and astrocytes). Using multiple BBB databases, the results of the final in silico transformer and XGBoost model achieved an area under the receiver operating characteristic curve of 0.88 on the held-out test dataset. Temozolomide (TMZ) and 21 randomly selected BBB permeable compounds (Pred scores = 1, indicating BBB-permeable) from the NPRL penetrated human BBB spheroid cells. No evidence suggests that ferulic acid or five BBB-impermeable compounds (Pred scores < 1.29423E−05, which designate compounds that pass through the human BBB) can pass through the spheroid cells of the BBB. Our validation of in vitro experiments indicated that the in silico prediction of small-molecule permeation in the BBB model is accurate. Transformer-based models like MegaMolBART, leveraging the SMILES representations of molecules, show great promise for applications in new drug discovery. These models have the potential to accelerate the development of novel targeted treatments for disorders of the central nervous system."
summary = summarizer(abstract, max_length = 100L)
summary_text = summary[[1]]$summary_text
print(summary_text)
summarizer = transformers$pipeline("summarization", model = "allenai/scibert_scivocab_uncased")
source("~/.active-rstudio-document", echo=TRUE)
summarizer = transformers$pipeline("summarization", model = "google/pegasus-xsum")
abstract = "Predicting the blood–brain barrier (BBB) permeability of small-molecule compounds using a novel artificial intelligence platform is necessary for drug discovery. Machine learning and a large language model on artificial intelligence (AI) tools improve the accuracy and shorten the time for new drug development. The primary goal of this research is to develop artificial intelligence (AI) computing models and novel deep learning architectures capable of predicting whether molecules can permeate the human blood–brain barrier (BBB). The in silico (computational) and in vitro (experimental) results were validated by the Natural Products Research Laboratories (NPRL) at China Medical University Hospital (CMUH). The transformer-based MegaMolBART was used as the simplified molecular input line entry system (SMILES) encoder with an XGBoost classifier as an in silico method to check if a molecule could cross through the BBB. We used Morgan or Circular fingerprints to apply the Morgan algorithm to a set of atomic invariants as a baseline encoder also with an XGBoost classifier to compare the results. BBB permeability was assessed in vitro using three-dimensional (3D) human BBB spheroids (human brain microvascular endothelial cells, brain vascular pericytes, and astrocytes). Using multiple BBB databases, the results of the final in silico transformer and XGBoost model achieved an area under the receiver operating characteristic curve of 0.88 on the held-out test dataset. Temozolomide (TMZ) and 21 randomly selected BBB permeable compounds (Pred scores = 1, indicating BBB-permeable) from the NPRL penetrated human BBB spheroid cells. No evidence suggests that ferulic acid or five BBB-impermeable compounds (Pred scores < 1.29423E−05, which designate compounds that pass through the human BBB) can pass through the spheroid cells of the BBB. Our validation of in vitro experiments indicated that the in silico prediction of small-molecule permeation in the BBB model is accurate. Transformer-based models like MegaMolBART, leveraging the SMILES representations of molecules, show great promise for applications in new drug discovery. These models have the potential to accelerate the development of novel targeted treatments for disorders of the central nervous system."
summary = summarizer(abstract, max_length = 100L)
summary_text = summary[[1]]$summary_text
print(summary_text)
summarizer = transformers$pipeline("summarization")
abstract = "The genome is a sequence that encodes the DNA, RNA, and proteins that orchestrate an organism’s function. We present Evo, a long-context genomic foundation model with a frontier architecture trained on millions of prokaryotic and phage genomes, and report scaling laws on DNA to complement observations in language and vision. Evo generalizes across DNA, RNA, and proteins, enabling zero-shot function prediction competitive with domain-specific language models and the generation of functional CRISPR-Cas and transposon systems, representing the first examples of protein-RNA and protein-DNA codesign with a language model. Evo also learns how small mutations affect whole-organism fitness and generates megabase-scale sequences with plausible genomic architecture. These prediction and generation capabilities span molecular to genomic scales of complexity, advancing our understanding and control of biology."
summary = summarizer(abstract, max_length = 100L)
summary_text = summary[[1]]$summary_text
print(summary_text)
summarizer = transformers$pipeline("summarization")
abstract = "The widespread adoption of electronic health record (EHRs) in healthcare systems has created a vast and continuously growing resource of clinical data and provides new opportunities for population-based research. In particular, the linking of EHRs to biospecimens and genomic data in biobanks may help address what has become a rate-limiting study for genetic research: the need for large sample sizes. The principal roadblock to capitalizing on these resources is the need to establish the validity of phenotypes extracted from the EHR. For psychiatric genetic research, this represents a particular challenge given that diagnosis is based on patient reports and clinician observations that may not be well-captured in billing codes or narrative records. This review addresses the opportunities and pitfalls in EHR-based phenotyping with a focus on their application to psychiatric genetic research. A growing number of studies have demonstrated that diagnostic algorithms with high positive predictive value can be derived from EHRs, especially when structured data are supplemented by text mining approaches. Such algorithms enable semi-automated phenotyping for large-scale case-control studies. In addition, the scale and scope of EHR databases have been used successfully to identify phenotypic subgroups and derive algorithms for longitudinal risk prediction. EHR-based genomics are particularly well-suited to rapid look-up replication of putative risk genes, studies of pleiotropy (phenomewide association studies or PheWAS), investigations of genetic networks and overlap across the phenome, and pharmacogenomic research. EHR phenotyping has been relatively under-utilized in psychiatric genomic research but may become a key component of efforts to advance precision psychiatry."
summary = summarizer(abstract, max_length = 100L)
summary_text = summary[[1]]$summary_text
print(summary_text)
qa_pipeline <- transformers$pipeline("question-answering")
abstract1 = "Predicting the blood–brain barrier (BBB) permeability of small-molecule compounds using a novel artificial intelligence platform is necessary for drug discovery. Machine learning and a large language model on artificial intelligence (AI) tools improve the accuracy and shorten the time for new drug development. The primary goal of this research is to develop artificial intelligence (AI) computing models and novel deep learning architectures capable of predicting whether molecules can permeate the human blood–brain barrier (BBB). The in silico (computational) and in vitro (experimental) results were validated by the Natural Products Research Laboratories (NPRL) at China Medical University Hospital (CMUH). The transformer-based MegaMolBART was used as the simplified molecular input line entry system (SMILES) encoder with an XGBoost classifier as an in silico method to check if a molecule could cross through the BBB. We used Morgan or Circular fingerprints to apply the Morgan algorithm to a set of atomic invariants as a baseline encoder also with an XGBoost classifier to compare the results. BBB permeability was assessed in vitro using three-dimensional (3D) human BBB spheroids (human brain microvascular endothelial cells, brain vascular pericytes, and astrocytes). Using multiple BBB databases, the results of the final in silico transformer and XGBoost model achieved an area under the receiver operating characteristic curve of 0.88 on the held-out test dataset. Temozolomide (TMZ) and 21 randomly selected BBB permeable compounds (Pred scores = 1, indicating BBB-permeable) from the NPRL penetrated human BBB spheroid cells. No evidence suggests that ferulic acid or five BBB-impermeable compounds (Pred scores < 1.29423E−05, which designate compounds that pass through the human BBB) can pass through the spheroid cells of the BBB. Our validation of in vitro experiments indicated that the in silico prediction of small-molecule permeation in the BBB model is accurate. Transformer-based models like MegaMolBART, leveraging the SMILES representations of molecules, show great promise for applications in new drug discovery. These models have the potential to accelerate the development of novel targeted treatments for disorders of the central nervous system."
abstract2 = "The widespread adoption of electronic health record (EHRs) in healthcare systems has created a vast and continuously growing resource of clinical data and provides new opportunities for population-based research. In particular, the linking of EHRs to biospecimens and genomic data in biobanks may help address what has become a rate-limiting study for genetic research: the need for large sample sizes. The principal roadblock to capitalizing on these resources is the need to establish the validity of phenotypes extracted from the EHR. For psychiatric genetic research, this represents a particular challenge given that diagnosis is based on patient reports and clinician observations that may not be well-captured in billing codes or narrative records. This review addresses the opportunities and pitfalls in EHR-based phenotyping with a focus on their application to psychiatric genetic research. A growing number of studies have demonstrated that diagnostic algorithms with high positive predictive value can be derived from EHRs, especially when structured data are supplemented by text mining approaches. Such algorithms enable semi-automated phenotyping for large-scale case-control studies. In addition, the scale and scope of EHR databases have been used successfully to identify phenotypic subgroups and derive algorithms for longitudinal risk prediction. EHR-based genomics are particularly well-suited to rapid look-up replication of putative risk genes, studies of pleiotropy (phenomewide association studies or PheWAS), investigations of genetic networks and overlap across the phenome, and pharmacogenomic research. EHR phenotyping has been relatively under-utilized in psychiatric genomic research but may become a key component of efforts to advance precision psychiatry."
abstract3 = "The genome is a sequence that encodes the DNA, RNA, and proteins that orchestrate an organism’s function. We present Evo, a long-context genomic foundation model with a frontier architecture trained on millions of prokaryotic and phage genomes, and report scaling laws on DNA to complement observations in language and vision. Evo generalizes across DNA, RNA, and proteins, enabling zero-shot function prediction competitive with domain-specific language models and the generation of functional CRISPR-Cas and transposon systems, representing the first examples of protein-RNA and protein-DNA codesign with a language model. Evo also learns how small mutations affect whole-organism fitness and generates megabase-scale sequences with plausible genomic architecture. These prediction and generation capabilities span molecular to genomic scales of complexity, advancing our understanding and control of biology."
qa1_1 <- qa_pipeline(list(question = "Why is predicting blood-brain barrier permeability important?", context = abstract1))
qa1_2 <- qa_pipeline(list(question = "How does the study improve drug candidate selection?", context = abstract1))
qa2_1 <- qa_pipeline(list(question = "What strategies are discussed for mitigating climate change?", context = abstract2))
qa2_2 <- qa_pipeline(list(question = "What are the key challenges mentioned in the paper?", context = abstract2))
print(qa1_1$answer)
qa1_1 <- qa_pipeline(list(question = "How good are AI tools at predicting blood-brain barrier permeability?", context = abstract1))
qa1_2 <- qa_pipeline(list(question = "How does the study improve drug candidate selection?", context = abstract1))
qa2_1 <- qa_pipeline(list(question = "What strategies are discussed for mitigating climate change?", context = abstract2))
qa2_2 <- qa_pipeline(list(question = "What are the key challenges mentioned in the paper?", context = abstract2))
print(qa1_1$answer)
print(qa1_2$answer)
qa2_1 <- qa_pipeline(list(question = "What is the importance of this study?", context = abstract2))
qa2_2 <- qa_pipeline(list(question = "What is the main resource used for phenotyping in this article?", context = abstract2))
print(qa1_1$answer)
print(qa1_2$answer)
print(qa2_1$answer)
print(qa2_2$answer)
qa3_1 <- qa_pipeline(list(question = "What is the name of the long-context genomic foundation model that they present?", context = abstract3))
qa3_2 <- qa_pipeline(list(question = "What is the genome?", context = abstract3))
print(qa3_1$answer)
print(qa3_2$answer)
english_abstract = "Accumulating evidence points to the impact of the gut microbiota in regulating various chronic inflammatory disorders such as cancers. The intestinal microbiome is not only influencing the spontaneous course of colon malignancies but also acts at distant sterile sites of neoplasia, mostly playing a detrimental role. By providing microbial-associated molecular patterns and potentially antigens sharing molecular mimicry with tumor antigens, our commensals modulate the local and the systemic immune tonus, eventually influencing tumor microenvironment. Complicating this algorithm, therapeutic interventions alter the delicate balance between the epithelium, the microbial community, and the intestinal immunity, governing the final clinical outcome. This seminar focused on the impact of the intestinal composition on the immunomodulatory and therapeutic activities of distinct compounds (alkylating agents, platinum salts and immunotherapies) used in oncology. This research opens up “the era of anticancer probiotics” aimed at restoring gut eubiosis for a better clinical outcome in cancer patients."
translator <- transformers$pipeline(
task = "translation",
model = "Helsinki-NLP/opus-mt-en-fr")
translation <- translator(english_abstract)
translated_text <- translation[[1]]$translation_text
print(translated_text)
english_abstract = "Accumulating evidence points to the impact of the gut microbiota in regulating various chronic inflammatory disorders such as cancers. The intestinal microbiome is not only influencing the spontaneous course of colon malignancies but also acts at distant sterile sites of neoplasia, mostly playing a detrimental role. By providing microbial-associated molecular patterns and potentially antigens sharing molecular mimicry with tumor antigens, our commensals modulate the local and the systemic immune tonus, eventually influencing tumor microenvironment. Complicating this algorithm, therapeutic interventions alter the delicate balance between the epithelium, the microbial community, and the intestinal immunity, governing the final clinical outcome. This seminar focused on the impact of the intestinal composition on the immunomodulatory and therapeutic activities of distinct compounds (alkylating agents, platinum salts and immunotherapies) used in oncology. This research opens up “the era of anticancer probiotics” aimed at restoring gut eubiosis for a better clinical outcome in cancer patients."
fr_translator <- transformers$pipeline(
task = "translation",
model = "Helsinki-NLP/opus-mt-en-fr")
fr_translation <- translator(english_abstract)
fr_translated_text <- translation[[1]]$translation_text
print(english_abstract)
print(fr_translated_text)
french_abstract = "Récemment, l’impact du microbiote intestinal dans diverses pathologies inflammatoires chroniques, dont le cancer, a été mis en évidence. Le microbiome intestinal régule l’évolution spontanée des tumeurs malignes du côlon et aussi la carcinogenèse extra-intestinale, jouant principalement un rôle délétère. En exprimant des motifs moléculaires associés aux microbes et, potentiellement, des antigènes partageant un mimétisme moléculaire avec des antigènes tumoraux, nos commensaux modulent le tonus immunitaire local et systémique, et peuvent influencer le microenvironnement tumoral. Compliquant cette interaction, les traitements contre le cancer altèrent l’équilibre entre épithélium, microbiote et immunité intestinale, dictant ainsi la réponse clinique. Ce séminaire se concentre sur l’impact de la composition du microbiote intestinal sur les propriétés thérapeutiques et immunomodulatrices de différents agents (agents alkylants, sels de platine et immunothérapies) utilisés en oncologie. Ce champ de recherche ouvre les portes vers « l’ère des probiotiques anti-cancer » visant à restaurer une eubiose intestinale, de manière à améliorer la réponse clinique des patients atteints de cancer."
en_translator <- transformers$pipeline(
task = "translation",
model = "Helsinki-NLP/opus-mt-fr-en")
en_translation <- translator(english_abstract)
en_translated_text <- translation[[1]]$translation_text
print(french_abstract)
print(en_translated_text)
english_abstract <- "Accumulating evidence points to the impact of the gut microbiota in regulating various chronic inflammatory disorders such as cancers. The intestinal microbiome is not only influencing the spontaneous course of colon malignancies but also acts at distant sterile sites of neoplasia, mostly playing a detrimental role. By providing microbial-associated molecular patterns and potentially antigens sharing molecular mimicry with tumor antigens, our commensals modulate the local and the systemic immune tonus, eventually influencing tumor microenvironment. Complicating this algorithm, therapeutic interventions alter the delicate balance between the epithelium, the microbial community, and the intestinal immunity, governing the final clinical outcome. This seminar focused on the impact of the intestinal composition on the immunomodulatory and therapeutic activities of distinct compounds (alkylating agents, platinum salts and immunotherapies) used in oncology. This research opens up “the era of anticancer probiotics” aimed at restoring gut eubiosis for a better clinical outcome in cancer patients."
french_abstract <- "Récemment, l’impact du microbiote intestinal dans diverses pathologies inflammatoires chroniques, dont le cancer, a été mis en évidence. Le microbiome intestinal régule l’évolution spontanée des tumeurs malignes du côlon et aussi la carcinogenèse extra-intestinale, jouant principalement un rôle délétère. En exprimant des motifs moléculaires associés aux microbes et, potentiellement, des antigènes partageant un mimétisme moléculaire avec des antigènes tumoraux, nos commensaux modulent le tonus immunitaire local et systémique, et peuvent influencer le microenvironnement tumoral. Compliquant cette interaction, les traitements contre le cancer altèrent l’équilibre entre épithélium, microbiote et immunité intestinale, dictant ainsi la réponse clinique. Ce séminaire se concentre sur l’impact de la composition du microbiote intestinal sur les propriétés thérapeutiques et immunomodulatrices de différents agents (agents alkylants, sels de platine et immunothérapies) utilisés en oncologie. Ce champ de recherche ouvre les portes vers « l’ère des probiotiques anti-cancer » visant à restaurer une eubiose intestinale, de manière à améliorer la réponse clinique des patients atteints de cancer."
fr_translator <- transformers$pipeline(
task = "translation",
model = "Helsinki-NLP/opus-mt-en-fr"
)
en_translator <- transformers$pipeline(
task = "translation",
model = "Helsinki-NLP/opus-mt-fr-en"
)
fr_translation <- fr_translator(english_abstract)
fr_translated_text <- fr_translation[[1]]$translation_text
en_translation <- en_translator(french_abstract)
en_translated_text <- en_translation[[1]]$translation_text
cat("Original English Abstract:\n", english_abstract, "\n\n")
cat("Translated to French:\n", fr_translated_text, "\n\n")
cat("Original French Abstract:\n", french_abstract, "\n\n")
cat("Translated to English:\n", en_translated_text, "\n")
fr_translation <- fr_translator(english_abstract)
fr_translated_text <- fr_translation[[1]]$translation_text
en_translation <- en_translator(fr_translated_text)
en_translated_text <- en_translation[[1]]$translation_text
cat("Original English Abstract:\n", english_abstract, "\n\n")
cat("Translated to French:\n", fr_translated_text, "\n\n")
cat("Translated Back to English:\n", en_translated_text, "\n")
drugs = read_csv("approved_drug_structure.csv")
library(tidyverse)
library(purrr)
library(progress)
library(tidymodels)
library(keras)
library(yardstick)
library(rcdk)
library(ranger)
library(kernlab)
library(xgboost)
library(themis)
#####################################################
# STEP 1 - CLEAN DATA
#####################################################
## LOAD DATASET
drugs = read_csv("approved_drug_structure.csv")
setwd("/Users/jaden/Desktop/bio564/final_proj")
library(tidyverse)
library(purrr)
library(progress)
library(tidymodels)
library(keras)
library(yardstick)
library(rcdk)
library(ranger)
library(kernlab)
library(xgboost)
library(themis)
#####################################################
# STEP 1 - CLEAN DATA
#####################################################
## LOAD DATASET
drugs = read_csv("approved_drug_structure.csv")
print(head(drugs))
print(nrow(drugs))
View(drugs)
